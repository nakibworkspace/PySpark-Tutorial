{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCdFEJ0ZTtEWBDVUlw4SGB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nakibworkspace/PySpark-Tutorial/blob/main/PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpark Basic Introduction**"
      ],
      "metadata": {
        "id": "7ldMjHPEMljA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7ZnWrK9BZCA"
      },
      "outputs": [],
      "source": [
        "import pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "pVzU9aBIBgOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a spark session\n",
        "spark= SparkSession.builder \\\n",
        "        .appName('Practice') \\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "RydT6RrHCBvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "qspkjOrMCNLR",
        "outputId": "91c9d910-afe0-49d6-8af2-c1685835dbb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fda565ff5e0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c9eb6bd37d18:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Practice</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here as we are wroking on local machine, there is only one cluster. But in cloud we can make multiple clusters."
      ],
      "metadata": {
        "id": "JDCd7l9HEuLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read a dataset wrt spark\n",
        "df_pyspark = spark.read.csv(\"/content/test1 - Sheet1.csv\")"
      ],
      "metadata": {
        "id": "Ff58oY82CPA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q75XH1GXDcAZ",
        "outputId": "9baa89dd-c9f6-4d0a-f788-bf1866ff7c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_c0: string, _c1: string]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#see the entire dataset\n",
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQfND9SwEV50",
        "outputId": "c7188600-b5c5-47ca-bf5f-4a06391df971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+\n",
            "|   _c0|_c1|\n",
            "+------+---+\n",
            "|  Name|age|\n",
            "|   raj| 26|\n",
            "|  ibna| 27|\n",
            "|raihan| 34|\n",
            "|  sami| 56|\n",
            "|ridwan| 22|\n",
            "+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.option('header','true').csv('/content/test1 - Sheet1.csv').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMfn1aRnEe5v",
        "outputId": "11f8ee57-94ed-40cf-f423-e36876f4412a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+\n",
            "|  Name|age|\n",
            "+------+---+\n",
            "|   raj| 26|\n",
            "|  ibna| 27|\n",
            "|raihan| 34|\n",
            "|  sami| 56|\n",
            "|ridwan| 22|\n",
            "+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.option('header','true').csv('/content/test1 - Sheet1.csv')"
      ],
      "metadata": {
        "id": "NwxjN4DsFib0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "yVhLrPpBFmMz",
        "outputId": "0ea99998-6b95-4b61-f6d0-2737712ed828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUKGHjBYKvUW",
        "outputId": "95247f12-90e9-463b-d35b-3d6886c6a5ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name='raj', age='26'),\n",
              " Row(Name='ibna', age='27'),\n",
              " Row(Name='raihan', age='34')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgvpwWsyMKaK",
        "outputId": "74f74c00-e7cf-4f43-eccd-89311ab2bf01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2nd Session** \\\n",
        "PySpark DataFrame \\\n",
        "Reading Dataset \\\n",
        "Checking the DataTypes of the column (Schema) \\\n",
        "Selecting columns and indexing \\\n",
        "Check describe option similar to Pandas \\\n",
        "Dropping columns \\\n",
        "Rename columns\n"
      ],
      "metadata": {
        "id": "IYZVDpuJMwbn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the last session code, we saw the age is shown as string where it was clearly an integer value. By default the pyspark thinks of every values as string, to change it .csv needs another attribute within it."
      ],
      "metadata": {
        "id": "pi4EyJ99OuDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=spark.read.option('header','true').csv('/content/test1 - Sheet1.csv',inferSchema=True)"
      ],
      "metadata": {
        "id": "LT3EkpewMQG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8Ythje2PG8v",
        "outputId": "268d6d21-02d7-451c-8f0d-4c30c675bd0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df_pyspark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "ScCMlsXsPJPg",
        "outputId": "17add012-09b0-4335-e32b-e366080bd6e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BYcWZpqPdrr",
        "outputId": "5c4e8e3f-cf52-4618-cea5-6e72d06aa3e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'age']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb7UWb9aP7J8",
        "outputId": "97fe8311-5dd6-4e12-dd43-8a396b714961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name='raj', age=26), Row(Name='ibna', age=27), Row(Name='raihan', age=34)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To select one column\n",
        "df_pyspark.select('Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYwlp1xfQDko",
        "outputId": "fa02e152-efe3-4948-b3d8-448b73223e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|  Name|\n",
            "+------+\n",
            "|   raj|\n",
            "|  ibna|\n",
            "|raihan|\n",
            "|  sami|\n",
            "|ridwan|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmvADj80RPbP",
        "outputId": "2f23a9f7-0797-4f4e-b492-47ffa8ed81e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'), ('age', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A3atShWRqWb",
        "outputId": "8613e906-fefc-49e9-a803-b34d75c1ae1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, Name: string, age: string]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKqxgi4rRwhq",
        "outputId": "941b5dfc-6568-4946-fe5a-95a3b0050680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----+------------------+\n",
            "|summary|Name|               age|\n",
            "+-------+----+------------------+\n",
            "|  count|   5|                 5|\n",
            "|   mean|NULL|              33.0|\n",
            "| stddev|NULL|13.564659966250536|\n",
            "|    min|ibna|                22|\n",
            "|    max|sami|                56|\n",
            "+-------+----+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Adding columns in dataframe\n",
        "df_pyspark=df_pyspark.withColumn('Age after 2 years',df_pyspark['Age']+2)"
      ],
      "metadata": {
        "id": "UKgBXNAKRzPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRoLAsLSVVaF",
        "outputId": "0898919e-db44-4001-d048-a5194ed38eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+-----------------+\n",
            "|  Name|age|Age after 2 years|\n",
            "+------+---+-----------------+\n",
            "|   raj| 26|               28|\n",
            "|  ibna| 27|               29|\n",
            "|raihan| 34|               36|\n",
            "|  sami| 56|               58|\n",
            "|ridwan| 22|               24|\n",
            "+------+---+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Dropping columns\n",
        "df_pyspark=df_pyspark.drop('Age after 2 years')"
      ],
      "metadata": {
        "id": "IiNufAX6Vfwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbGyzCroVlLn",
        "outputId": "1d965b5c-9d1d-4457-f76a-4e4da8f9c5ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+\n",
            "|  Name|age|\n",
            "+------+---+\n",
            "|   raj| 26|\n",
            "|  ibna| 27|\n",
            "|raihan| 34|\n",
            "|  sami| 56|\n",
            "|ridwan| 22|\n",
            "+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Rename the column\n",
        "df_pyspark.withColumnRenamed('Name','New Name')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk9wx9lqVmiA",
        "outputId": "6cc4527f-c7ed-4a07-9fe7-8b057317ead9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[New Name: string, age: int]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.withColumnRenamed('Name','New Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o57ApJo6VuMa",
        "outputId": "fddc84ac-c586-42f3-efc7-6e17ef4084e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---+\n",
            "|New Name|age|\n",
            "+--------+---+\n",
            "|     raj| 26|\n",
            "|    ibna| 27|\n",
            "|  raihan| 34|\n",
            "|    sami| 56|\n",
            "|  ridwan| 22|\n",
            "+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpark Handling Missing Values** \\\n",
        "Dropping cols \\\n",
        "Dropping rows \\\n",
        "various params in dropping functionality \\\n",
        "handling missing values by mean, median, mode"
      ],
      "metadata": {
        "id": "OPOVqaQWV9ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2_pyspark=spark.read.csv(\"/content/test1 - Sheet1-2.csv\",header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "eBZWzp-yVyXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68iG2XVrX9jQ",
        "outputId": "59e551e3-a23d-437f-e492-a77662964784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----------+------+\n",
            "|  Name| age|experience |salary|\n",
            "+------+----+-----------+------+\n",
            "|   raj|  26|         10| 30000|\n",
            "|  ibna|  27|          8| 25000|\n",
            "|raihan|  34|          4| 20000|\n",
            "|  sami|  56|          3| 20000|\n",
            "|ridwan|  22|          1| 15000|\n",
            "| nafis|  23|          2| 18000|\n",
            "|  obhi|NULL|       NULL| 40000|\n",
            "|  NULL|  34|         10| 38000|\n",
            "|  NULL|  46|       NULL|  NULL|\n",
            "+------+----+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##dropping the cols\n",
        "df2_pyspark.drop('Name')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCoYjWTpYHS_",
        "outputId": "11d1b58f-1e8d-434c-8da6-1c816817ca7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[age: int, experience : int, salary: int]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ENPoTLaYWdA",
        "outputId": "a629d05d-c017-427d-f7d2-8a62ff82a171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----------+------+\n",
            "|  Name| age|experience |salary|\n",
            "+------+----+-----------+------+\n",
            "|   raj|  26|         10| 30000|\n",
            "|  ibna|  27|          8| 25000|\n",
            "|raihan|  34|          4| 20000|\n",
            "|  sami|  56|          3| 20000|\n",
            "|ridwan|  22|          1| 15000|\n",
            "| nafis|  23|          2| 18000|\n",
            "|  obhi|NULL|       NULL| 40000|\n",
            "|  NULL|  34|         10| 38000|\n",
            "|  NULL|  46|       NULL|  NULL|\n",
            "+------+----+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2_pyspark.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKVDn9EqYdUg",
        "outputId": "a6ff4183-a746-4cb0-e861-4e07630791c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+-----------+------+\n",
            "|  Name|age|experience |salary|\n",
            "+------+---+-----------+------+\n",
            "|   raj| 26|         10| 30000|\n",
            "|  ibna| 27|          8| 25000|\n",
            "|raihan| 34|          4| 20000|\n",
            "|  sami| 56|          3| 20000|\n",
            "|ridwan| 22|          1| 15000|\n",
            "| nafis| 23|          2| 18000|\n",
            "+------+---+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in drop() there are some different params"
      ],
      "metadata": {
        "id": "JeHtXp-ey2Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##any==how\n",
        "df2_pyspark.na.drop(how=\"any\").show() #drops only if all the cols are null\n",
        "##how=all\n",
        "df2_pyspark.na.drop(how=\"all\").show() #drops row if one col is null"
      ],
      "metadata": {
        "id": "y54YQmtNZA4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0034210-7820-4610-f65c-79229794ad43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+-----------+------+\n",
            "|  Name|age|experience |salary|\n",
            "+------+---+-----------+------+\n",
            "|   raj| 26|         10| 30000|\n",
            "|  ibna| 27|          8| 25000|\n",
            "|raihan| 34|          4| 20000|\n",
            "|  sami| 56|          3| 20000|\n",
            "|ridwan| 22|          1| 15000|\n",
            "| nafis| 23|          2| 18000|\n",
            "+------+---+-----------+------+\n",
            "\n",
            "+------+----+-----------+------+\n",
            "|  Name| age|experience |salary|\n",
            "+------+----+-----------+------+\n",
            "|   raj|  26|         10| 30000|\n",
            "|  ibna|  27|          8| 25000|\n",
            "|raihan|  34|          4| 20000|\n",
            "|  sami|  56|          3| 20000|\n",
            "|ridwan|  22|          1| 15000|\n",
            "| nafis|  23|          2| 18000|\n",
            "|  obhi|NULL|       NULL| 40000|\n",
            "|  NULL|  34|         10| 38000|\n",
            "|  NULL|  46|       NULL|  NULL|\n",
            "+------+----+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##threshold\n",
        "df2_pyspark.na.drop(how=\"any\", thresh=2).show() #atleast row has to have two not null value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4PIAfXezZS0",
        "outputId": "e327547d-0fb1-4c2e-f5e1-80939bc930cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----------+------+\n",
            "|  Name| age|experience |salary|\n",
            "+------+----+-----------+------+\n",
            "|   raj|  26|         10| 30000|\n",
            "|  ibna|  27|          8| 25000|\n",
            "|raihan|  34|          4| 20000|\n",
            "|  sami|  56|          3| 20000|\n",
            "|ridwan|  22|          1| 15000|\n",
            "| nafis|  23|          2| 18000|\n",
            "|  obhi|NULL|       NULL| 40000|\n",
            "|  NULL|  34|         10| 38000|\n",
            "+------+----+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2_pyspark.na.drop(how=\"any\", subset=['experience ']).show() #drops only if experience is null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Puf8u91XzvS6",
        "outputId": "bf0951cb-c18b-419b-86da-6d98a680bf0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+-----------+------+\n",
            "|  Name|age|experience |salary|\n",
            "+------+---+-----------+------+\n",
            "|   raj| 26|         10| 30000|\n",
            "|  ibna| 27|          8| 25000|\n",
            "|raihan| 34|          4| 20000|\n",
            "|  sami| 56|          3| 20000|\n",
            "|ridwan| 22|          1| 15000|\n",
            "| nafis| 23|          2| 18000|\n",
            "|  NULL| 34|         10| 38000|\n",
            "+------+---+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2_pyspark.na.drop(how=\"any\", subset=['age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uITQ68Fs18xi",
        "outputId": "8621727d-4c68-4fb9-e79e-f2a7d82ecc65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+-----------+------+\n",
            "|  Name|age|experience |salary|\n",
            "+------+---+-----------+------+\n",
            "|   raj| 26|         10| 30000|\n",
            "|  ibna| 27|          8| 25000|\n",
            "|raihan| 34|          4| 20000|\n",
            "|  sami| 56|          3| 20000|\n",
            "|ridwan| 22|          1| 15000|\n",
            "| nafis| 23|          2| 18000|\n",
            "|  NULL| 34|         10| 38000|\n",
            "|  NULL| 46|       NULL|  NULL|\n",
            "+------+---+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Filling the missing value\n",
        "df2_pyspark.na.fill('Missing Values').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1NleTy75K1g",
        "outputId": "8950fd4a-15fa-42f3-eb8f-23eb2ae29cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+-----------+------+\n",
            "|          Name| age|experience |salary|\n",
            "+--------------+----+-----------+------+\n",
            "|           raj|  26|         10| 30000|\n",
            "|          ibna|  27|          8| 25000|\n",
            "|        raihan|  34|          4| 20000|\n",
            "|          sami|  56|          3| 20000|\n",
            "|        ridwan|  22|          1| 15000|\n",
            "|         nafis|  23|          2| 18000|\n",
            "|          obhi|NULL|       NULL| 40000|\n",
            "|Missing Values|  34|         10| 38000|\n",
            "|Missing Values|  46|       NULL|  NULL|\n",
            "+--------------+----+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the Null only replaced by missing values cause the missing values changes can be done only in strings.\n"
      ],
      "metadata": {
        "id": "t27aqCdU6uwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY4gl3hu5f9z",
        "outputId": "18881bee-3442-43d3-bbc1-fa55fecfc9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- experience : integer (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gotta cast the int cols to string first\n",
        "from pyspark.sql.functions import col\n",
        "df2_pyspark= df2_pyspark.withColumn(\"age\",col(\"age\").cast(\"string\")) \\\n",
        "                        .withColumn(\"experience \",col(\"experience \").cast(\"string\")) \\\n",
        "                        .withColumn(\"Salary\",col(\"Salary\").cast(\"string\"))"
      ],
      "metadata": {
        "id": "t02r5vGV6fLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6NHJsZJ7gd-",
        "outputId": "5e06564f-2cb9-4b5d-811f-6108b49e1c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: string (nullable = true)\n",
            " |-- experience : string (nullable = true)\n",
            " |-- Salary: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2_pyspark.na.fill('Missing Values').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6HeYU8O9R-E",
        "outputId": "f7cd0d81-6de5-4483-a5d1-a8562d2132f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------+--------------+--------------+\n",
            "|          Name|           age|   experience |        Salary|\n",
            "+--------------+--------------+--------------+--------------+\n",
            "|           raj|            26|            10|         30000|\n",
            "|          ibna|            27|             8|         25000|\n",
            "|        raihan|            34|             4|         20000|\n",
            "|          sami|            56|             3|         20000|\n",
            "|        ridwan|            22|             1|         15000|\n",
            "|         nafis|            23|             2|         18000|\n",
            "|          obhi|Missing Values|Missing Values|         40000|\n",
            "|Missing Values|            34|            10|         38000|\n",
            "|Missing Values|            46|Missing Values|Missing Values|\n",
            "+--------------+--------------+--------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3_pyspark=spark.read.csv(\"/content/test1 - Sheet1-2.csv\",header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "xXfXaCEm_SpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkRtinUk_tVu",
        "outputId": "0cc92cc7-e4f5-4fa7-9e6e-5ad08e84c6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- experience : integer (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fill the null values with mean, median and mode we are going to use Imputer function."
      ],
      "metadata": {
        "id": "0s-vhZG5-Wfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer= Imputer(\n",
        "    inputCols=['age','experience ', 'salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['age','experience ','salary']]\n",
        ").setStrategy(\"mean\")"
      ],
      "metadata": {
        "id": "jOAagEtb9Y5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add imputation cols to df\n",
        "imputer.fit(df3_pyspark).transform(df3_pyspark).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFbN9DQ4_ACZ",
        "outputId": "3086aad2-7bb8-4b0d-8776-32fb30574f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----------+------+-----------+-------------------+--------------+\n",
            "|  Name| age|experience |salary|age_imputed|experience _imputed|salary_imputed|\n",
            "+------+----+-----------+------+-----------+-------------------+--------------+\n",
            "|   raj|  26|         10| 30000|         26|                 10|         30000|\n",
            "|  ibna|  27|          8| 25000|         27|                  8|         25000|\n",
            "|raihan|  34|          4| 20000|         34|                  4|         20000|\n",
            "|  sami|  56|          3| 20000|         56|                  3|         20000|\n",
            "|ridwan|  22|          1| 15000|         22|                  1|         15000|\n",
            "| nafis|  23|          2| 18000|         23|                  2|         18000|\n",
            "|  obhi|NULL|       NULL| 40000|         33|                  5|         40000|\n",
            "|  NULL|  34|         10| 38000|         34|                 10|         38000|\n",
            "|  NULL|  46|       NULL|  NULL|         46|                  5|         25750|\n",
            "+------+----+-----------+------+-----------+-------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer= Imputer(\n",
        "    inputCols=['age','experience ','salary'],\n",
        "    outputCols=[\"{}_imputet\".format(c) for c in ['age','experience ','salary']]\n",
        ").setStrategy(\"median\")"
      ],
      "metadata": {
        "id": "1xVoe3-P_OSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer.fit(df3_pyspark).transform(df3_pyspark).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm4lv4v0AkiE",
        "outputId": "ddb9e590-73ce-42d3-dfa6-41851e5f7112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----------+------+-----------+-------------------+--------------+\n",
            "|  Name| age|experience |salary|age_imputet|experience _imputet|salary_imputet|\n",
            "+------+----+-----------+------+-----------+-------------------+--------------+\n",
            "|   raj|  26|         10| 30000|         26|                 10|         30000|\n",
            "|  ibna|  27|          8| 25000|         27|                  8|         25000|\n",
            "|raihan|  34|          4| 20000|         34|                  4|         20000|\n",
            "|  sami|  56|          3| 20000|         56|                  3|         20000|\n",
            "|ridwan|  22|          1| 15000|         22|                  1|         15000|\n",
            "| nafis|  23|          2| 18000|         23|                  2|         18000|\n",
            "|  obhi|NULL|       NULL| 40000|         27|                  4|         40000|\n",
            "|  NULL|  34|         10| 38000|         34|                 10|         38000|\n",
            "|  NULL|  46|       NULL|  NULL|         46|                  4|         20000|\n",
            "+------+----+-----------+------+-----------+-------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer= Imputer(\n",
        "    inputCols=['age','experience ','salary'],\n",
        "    outputCols=[\"{}_imputet\".format(c) for c in ['age','experience ','salary']]\n",
        ").setStrategy(\"mode\")"
      ],
      "metadata": {
        "id": "6iPOvCOuAqX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer.fit(df3_pyspark).transform(df3_pyspark).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWY2Tb6ZAuNY",
        "outputId": "2af84035-70d6-4c9c-dbc7-bd91b75077e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----------+------+-----------+-------------------+--------------+\n",
            "|  Name| age|experience |salary|age_imputet|experience _imputet|salary_imputet|\n",
            "+------+----+-----------+------+-----------+-------------------+--------------+\n",
            "|   raj|  26|         10| 30000|         26|                 10|         30000|\n",
            "|  ibna|  27|          8| 25000|         27|                  8|         25000|\n",
            "|raihan|  34|          4| 20000|         34|                  4|         20000|\n",
            "|  sami|  56|          3| 20000|         56|                  3|         20000|\n",
            "|ridwan|  22|          1| 15000|         22|                  1|         15000|\n",
            "| nafis|  23|          2| 18000|         23|                  2|         18000|\n",
            "|  obhi|NULL|       NULL| 40000|         34|                 10|         40000|\n",
            "|  NULL|  34|         10| 38000|         34|                 10|         38000|\n",
            "|  NULL|  46|       NULL|  NULL|         46|                 10|         20000|\n",
            "+------+----+-----------+------+-----------+-------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpark Dataframes** \\\n",
        "filter operation \\\n",
        "&,|,== \\\n",
        "~"
      ],
      "metadata": {
        "id": "3JcT-wKvzWCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filter Operations**"
      ],
      "metadata": {
        "id": "pAcBWeAFzqy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### salary of people less than or equal to 20000\n",
        "df2_pyspark.filter(\"salary<=20000\").show()"
      ],
      "metadata": {
        "id": "pvquGe2oA214",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5cd62d2-985c-4e3a-fe3f-9bde03b38fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+-----------+------+\n",
            "|  Name|age|experience |Salary|\n",
            "+------+---+-----------+------+\n",
            "|raihan| 34|          4| 20000|\n",
            "|  sami| 56|          3| 20000|\n",
            "|ridwan| 22|          1| 15000|\n",
            "| nafis| 23|          2| 18000|\n",
            "+------+---+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2_pyspark.filter(\"salary<=20000\").select(['name','age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUYjL7fkz7Gi",
        "outputId": "d30f5dfe-e75a-4ac2-d441-fa3a7446eeaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+\n",
            "|  name|age|\n",
            "+------+---+\n",
            "|raihan| 34|\n",
            "|  sami| 56|\n",
            "|ridwan| 22|\n",
            "| nafis| 23|\n",
            "+------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#two conditions\n",
        "df2_pyspark.filter((df2_pyspark['salary'] <= 20000) & (df2_pyspark['salary'] >= 15000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO9OYSt00DbO",
        "outputId": "1f9629c9-6e5a-4404-af7a-e784d00c9f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+-----------+------+\n",
            "|  Name|age|experience |Salary|\n",
            "+------+---+-----------+------+\n",
            "|raihan| 34|          4| 20000|\n",
            "|  sami| 56|          3| 20000|\n",
            "|ridwan| 22|          1| 15000|\n",
            "| nafis| 23|          2| 18000|\n",
            "+------+---+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2_pyspark.filter((df2_pyspark['salary'] <= 20000) | (df2_pyspark['salary'] >= 15000)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr_ozqaU0s3x",
        "outputId": "41eaa3de-8fd1-40f1-8f8a-ec717163b3f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----------+------+\n",
            "|  Name| age|experience |Salary|\n",
            "+------+----+-----------+------+\n",
            "|   raj|  26|         10| 30000|\n",
            "|  ibna|  27|          8| 25000|\n",
            "|raihan|  34|          4| 20000|\n",
            "|  sami|  56|          3| 20000|\n",
            "|ridwan|  22|          1| 15000|\n",
            "| nafis|  23|          2| 18000|\n",
            "|  obhi|NULL|       NULL| 40000|\n",
            "|  NULL|  34|         10| 38000|\n",
            "+------+----+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2_pyspark.filter(df2_pyspark['salary']<=20000).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH09v9rz00h4",
        "outputId": "b195e337-6146-4ed2-aa91-88bafc008e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---+-----------+------+\n",
            "|  Name|age|experience |Salary|\n",
            "+------+---+-----------+------+\n",
            "|raihan| 34|          4| 20000|\n",
            "|  sami| 56|          3| 20000|\n",
            "|ridwan| 22|          1| 15000|\n",
            "| nafis| 23|          2| 18000|\n",
            "+------+---+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpark GroupBy And Aggregate Function**"
      ],
      "metadata": {
        "id": "6CMVdpbo2D6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df4_pyspark=spark.read.csv('/content/Sheet2 - Sheet1-2.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "TCpS4cvV1Err"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIOmjGsO4ViN",
        "outputId": "f8b0b46a-dda5-4a2e-961a-1cc02b09b04a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+------+\n",
            "|  Name|   Department|Salary|\n",
            "+------+-------------+------+\n",
            "| Nakib|Data Science | 10000|\n",
            "| Nakib|          IOT|  5000|\n",
            "|  Ibna|     Big Data|  4000|\n",
            "| Nakib|     Big Data|  4000|\n",
            "|  Ibna|Data Science |  3000|\n",
            "|Raihan|Data Science | 20000|\n",
            "|Raihan|          IOT| 10000|\n",
            "|Raihan|     Big Data|  5000|\n",
            "|  Alif|Data Science | 10000|\n",
            "|  Alif|     Big Data| 25000|\n",
            "+------+-------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USnnTjQx4XV4",
        "outputId": "2cf2d440-c193-49c5-c228-396677a44375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Department: string (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#groupby\n",
        "#maximum salary of all people\n",
        "df4_pyspark.groupBy('Name').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYo4qw3u4idQ",
        "outputId": "f39c5a1e-5f51-4539-9abf-b8569def5ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+\n",
            "|  Name|sum(Salary)|\n",
            "+------+-----------+\n",
            "|Raihan|      35000|\n",
            "|  Alif|      35000|\n",
            "|  Ibna|       7000|\n",
            "| Nakib|      19000|\n",
            "+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Max salary each person getting\n",
        "df4_pyspark.groupBy('Name').max().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By4FuaXUGSBw",
        "outputId": "ef803bb4-3f74-4c0f-cb17-336e4d3cd54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+\n",
            "|  Name|max(Salary)|\n",
            "+------+-----------+\n",
            "|Raihan|      20000|\n",
            "|  Alif|      25000|\n",
            "|  Ibna|       4000|\n",
            "| Nakib|      10000|\n",
            "+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Min salary\n",
        "df4_pyspark.groupBy('Name').min().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abBefRVKHE1n",
        "outputId": "d41354ce-91ae-4860-f393-db9fcc6bcf0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+\n",
            "|  Name|min(Salary)|\n",
            "+------+-----------+\n",
            "|Raihan|       5000|\n",
            "|  Alif|      10000|\n",
            "|  Ibna|       3000|\n",
            "| Nakib|       4000|\n",
            "+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P7gHdv24zUY",
        "outputId": "9e6de720-fb0e-4332-a292-f7c67fb930a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+------+\n",
            "|  Name|   Department|Salary|\n",
            "+------+-------------+------+\n",
            "| Nakib|Data Science | 10000|\n",
            "| Nakib|          IOT|  5000|\n",
            "|  Ibna|     Big Data|  4000|\n",
            "| Nakib|     Big Data|  4000|\n",
            "|  Ibna|Data Science |  3000|\n",
            "|Raihan|Data Science | 20000|\n",
            "|Raihan|          IOT| 10000|\n",
            "|Raihan|     Big Data|  5000|\n",
            "|  Alif|Data Science | 10000|\n",
            "|  Alif|     Big Data| 25000|\n",
            "+------+-------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### groupby department which gives max salary\n",
        "df4_pyspark.groupBy('Department').sum().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR-1xRvaC6CL",
        "outputId": "5c0627c1-9c8c-4067-8ed2-381cf45809eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----------+\n",
            "|   Department|sum(Salary)|\n",
            "+-------------+-----------+\n",
            "|          IOT|      15000|\n",
            "|     Big Data|      38000|\n",
            "|Data Science |      43000|\n",
            "+-------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4_pyspark.groupBy('Department').mean().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Wski3PKFdlR",
        "outputId": "28132f0c-27c1-4895-fef7-107ea27329d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----------+\n",
            "|   Department|avg(Salary)|\n",
            "+-------------+-----------+\n",
            "|          IOT|     7500.0|\n",
            "|     Big Data|     9500.0|\n",
            "|Data Science |    10750.0|\n",
            "+-------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4_pyspark.groupBy('Department').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gsaoiMwFqS8",
        "outputId": "982c5f2d-cbd4-4259-e088-be1005b93fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+\n",
            "|   Department|count|\n",
            "+-------------+-----+\n",
            "|          IOT|    2|\n",
            "|     Big Data|    4|\n",
            "|Data Science |    4|\n",
            "+-------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4_pyspark.agg({'Salary': 'sum'}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfrZLEzQFst6",
        "outputId": "869d2c3f-b092-4bc9-98c8-6d781760c630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|sum(Salary)|\n",
            "+-----------+\n",
            "|      96000|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SFfxJxGtGB2J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}